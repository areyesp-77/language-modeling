{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Intergación de procesos ⚓\n",
        "\n",
        "Además de trabajar con las estructuras de control, en esta sesión incluiremos otro tipo de dato que es muy útil en el trabajo con lenguaje natural: tuplas\n",
        "\n",
        "Antes de trabajar con este contenido, es importante saber cómo resolvieron (o se resuelve) la práctica de la sesión previa.\n",
        "\n",
        "A continuación, la consigna:"
      ],
      "metadata": {
        "id": "V0jRQIjm1g1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Práctica\n",
        "\n",
        "* Hagan un código para eliminar las palabras funcionales del texto de **prosody**\n",
        "\n",
        "* Posteriormente, modifiquen el código para eliminar los signos de puntuación.\n",
        "\n",
        "* Obtengan las frecuencias de todas las palabras y, por último, utilicen las secuencias de control para imprimir:\n",
        "  * Frequency of WORD = INT: accepted word, si las palabras tienen frecuencia igual a 2\n",
        "  * Frequency of WORD = INT >>> unexpected word, si ienen frecuencia mayor a 2\n",
        "  * Frequency of WORD = INT --- rejected word, de lo contrario"
      ],
      "metadata": {
        "id": "m_nJZxvRLhFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Un posible código para resolver la práctica es el siguiente:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "prosody = 'Prosody is the study of the tune and rhythm of speech and how these features contribute to meaning. Prosody is the study of those aspects of speech that typically apply to a level above that of the individual phoneme and very often to sequences of words (in prosodic phrases). Features above the level of the phoneme (or “segment”) are referred to as suprasegmentals.'\n",
        "\n",
        "prosodyLower = prosody.lower().split()\n",
        "stoplist = ['of', 'the', 'in', 'a', 'an', 'with', 'and']\n",
        "\n",
        "prosodyClean = (' '.join(word for word in prosodyLower if word not in stoplist))\n",
        "print(prosodyClean)\n",
        "\n",
        "punctuation = '.,;:[]()$%'\n",
        "prosodyClean2 = (''.join(punct for punct in prosodyClean if punct not in punctuation))\n",
        "print(prosodyClean2)\n",
        "\n",
        "counter = 0\n",
        "prosodyClean3 = prosodyClean2.split()\n",
        "for i in prosodyClean3:\n",
        "    counter = prosodyClean3.count(i)\n",
        "    #print(i, counter)\n",
        "    if counter == 2:\n",
        "        print('Frequency of', i.upper(), '=', counter, ': accepted word')\n",
        "    elif counter >= 3:\n",
        "        print('Frequency of', i.upper(), '=', counter, '>>> unexpected word')\n",
        "    else:\n",
        "        print('Frequency of', i.upper(), '=', counter, ' --- rejected word')\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "JK2NtgwjwPSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Integración de tuplas\n",
        "\n",
        "Último tipo de dato para las secuencias: tuplas (dos elementos están relacionados {'a=1', 'b=2', 'c=3}.\n",
        "\n",
        "Los elementos en la tupla se insertan entre llaves {}. Las tuplas más comunes son los diccionarios.\n",
        "\n",
        "En este código vamos a crear un diccionario vacío para guardar los elementos de la lista junto con su frecuencia.\n",
        "\n",
        "Con ello, eliminaremos los tokens de nuestra representación y nos quedaremos con los types + su frecuencia (tokens)."
      ],
      "metadata": {
        "id": "bQaKH8D5w5RD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frecuencia_dictionary = {}\n",
        "for i in prosodyClean3:\n",
        "    frecuencia_dictionary[i] = frecuencia_dictionary.get(i, 0) + 1\n",
        "print(frecuencia_dictionary)"
      ],
      "metadata": {
        "id": "zSYgG2TTw08F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora volvemos con las estructuras de control para extraer sólo las palabras con determinada frecuencia\n",
        "\n",
        "**Ojo** que aquí iteramos sobre el diccionario, no sobre la lista"
      ],
      "metadata": {
        "id": "vgXNx1diy8Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, freqs in frecuencia_dictionary.items():\n",
        "    #print(i, freqs)\n",
        "    if freqs == 1:\n",
        "        print(i, '=', freqs)\n",
        "    #elif freqs in range(2, 3):\n",
        "    else:\n",
        "        print(i, '=', freqs, 'higher than expected')"
      ],
      "metadata": {
        "id": "q377YMPGy0_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de un realizar una práctica global, vamos a trabajar en paralelo para obtener los **types** de un STR, así como su frecuencia.\n",
        "\n",
        "Partimos del siguiente STR:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gBuzQx-Y3WX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = 'El objetivo es identificar características en datos controlados acerca de los rasgos acústicos que nos permitan la identificación de emociones en maya yucateco. Para ello, se toman como base los resultados de investigaciones que han trabajado al respecto. En la literatura especializada se menciona que el HNR es un parámetro fiable para discriminar las emociones. El resto de estudios que se revisaron también mencionan que hay pistas acústicas en estos componentes para identificar emociones. Estos estudios se han realizado para el inglés o lenguas que, acústicamente, tienen sistemas diferentes al maya.'\n"
      ],
      "metadata": {
        "id": "QdWtw8GXz3Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Vamos a crear una variable para eliminar los signos de puntuación para quitarlos antes de convertir a lista\n",
        "##Ojo: acá los signos operan a nivel STR\n",
        "signos = '.,;:[]()$%\"-_'\n"
      ],
      "metadata": {
        "id": "D_-Le6-F3_5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Quitamos los signos del STR\n",
        "\n",
        "corpus_cleanSignos = (''.join(signo for signo in corpus if signo not in signos))\n",
        "print(corpus_cleanSignos)"
      ],
      "metadata": {
        "id": "GP1zCt204NiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Ahora convertimos a LIST\n",
        "\n",
        "corpus_cleanSignos = corpus_cleanSignos.lower().split()\n"
      ],
      "metadata": {
        "id": "XwVQvppX4SoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Creamos nuestra variable con las palabras funcionales.\n",
        "##Ojo: acá es una LIST\n",
        "stoplist_ES = [\"el\", \"la\", \"los\", \"las\", \"un\", \"una\", \"y\", \"o\", \"en\", \"con\", \"de\", \"del\"]\n"
      ],
      "metadata": {
        "id": "GPDq6sy14ZQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Limpiamos el corpus\n",
        "\n",
        "corpus_cleanStop = (' '.join(w for w in corpus_cleanSignos if w not in stoplist_ES)).split()\n",
        "print(corpus_cleanStop)"
      ],
      "metadata": {
        "id": "uRd3Q6QK4kGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Finalmente, guardamos la lista, ordenada alfabéticamente, en otra variable\n",
        "\n",
        "corpus_final = sorted(corpus_cleanStop)\n",
        "print(corpus_final)"
      ],
      "metadata": {
        "id": "5otEAHFi4vjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Usamos el método len para saber el tamaño del corpus\n",
        "print(len(corpus_final), 'palabras en el corpus')"
      ],
      "metadata": {
        "id": "xcI5oG7f48qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Creamos el diccionario y contamos la frecuencia de cada ítem\n",
        "\n",
        "lexicon = {}\n",
        "for i in corpus_final:\n",
        "    lexicon[i] = lexicon.get(i, 0)+1\n",
        "print(lexicon)\n"
      ],
      "metadata": {
        "id": "4GbMA3an5KIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Obtenemos la frecuencia de cada type\n",
        "for i, tokens in lexicon.items():\n",
        "  print(i, tokens)"
      ],
      "metadata": {
        "id": "lY674Sko5XTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Práctica global\n",
        "\n",
        "* Creen el código para obtener todos los types del corpus, así como su frecuencia\n",
        "* No se olviden de eliminar palabras funcionales y signos de puntuación\n",
        "* Nota: para no crear varias variables ni estar cambiando el tipo de dato, primero quiten los signos del STR\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "corpus = 'All recordings in both quiet and noisy environment conditions use the same set of ten parallel sentences with different contexts, and each sentence is asked to be uttered in four different emotions: happy, sad, angry, and neutral. The order of sentences and emotions are randomized during the recording. For each speaker, we have at least 80 successfully performed and correctly pronounced utterances'\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lqGyaPux5m3E"
      }
    }
  ]
}